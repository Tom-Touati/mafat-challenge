{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresh Idea\n",
    "## separate one/zero activity of domains\n",
    "- replace zeros by minus one\n",
    "- calculate the class activity for 3 hours bins for each domain\n",
    "- calculate the user activity for gaussian around center of 3 hour bins\n",
    "- calculate the likelihood of the person being a 1/-1 in that time \n",
    "- add user general metrics including domain cls activity and usage patterns\n",
    "\n",
    "### questions\n",
    "- how to take into account times when the person used a website when others didnt?\n",
    "- how to give likelihood when the person didn't show any nearby activity?\n",
    "- what if he used a similar website at same time but more nich? \n",
    "- how to average the bins weighted by the significance of that bin?\n",
    "- how to give weight to the magnitude of number of users entering? probability of 1 with confidence\n",
    "- what about sparse websites?\n",
    "- how to not let times where there are no activity take a lot of weight?\n",
    "### enhancements\n",
    "- create graph embedding of urls\n",
    "- for each bin, calculate the metric per url\n",
    "- instead of only looking at the specific website, take into account websites with similar usages,\n",
    "  for example looking at same domain_cls usage in gaussian around bin, or looking at domain embeddings and looking at the activity in similar embeddings weighted by the distance in the embedding space\n",
    "\n",
    "### NOTICE:\n",
    "the data itself will use all domains, even ones that the person never used. this could be an issue. \n",
    "first of all the fact that the person doesnt use them is an indication. we \n",
    "- we might want to take the niche websites and sum them up\n",
    "- we might want to remove them\n",
    "\n",
    "IDEA!\n",
    "- use different features for different people\n",
    "- make an ensemble that can differentiate between different users\n",
    "- take the people that get a wrong prediction and see if a classifier that is more \"fringe\" can classify them better\n",
    "- for example another tree classifier that takes a smaller amount of features to give more opportunity to fringe websites\n",
    "can create a classifier for each user type \n",
    "can take number of usages for each domain, and cluster people or PCA\n",
    "clustering is good - I can create a classifier for each cluster, from each cluster take all of the available data for all of the visited domains, and create a classifier for them. use only data from those users or all users that used one of the websites, plus the general model, for each cluster - use cluster model and general model.\n",
    "also - I can multiply the features by the log of usages\n",
    "\n",
    "another idea is to simply average the most prominent websites weighted by the specific user usages, and the general usage\n",
    "\n",
    "USER CLUSTER AS FEATURE - or PCA coefficients\n",
    "\n",
    "an idea - see how chaotic are the subject's patterns, if it's too predictable then it might be a bot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import ray\n",
    "from modin.db_conn import ModinDatabaseConnection\n",
    "from modin.config import NPartitions,RangePartitioning\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"] = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiMGMyZjIyZC0xMjQzLTQxNjQtYjZjZC0wMTRiZmJmZmRlZjYifQ==\"\n",
    "    # !export MODIN_CPUS=2\n",
    "# n_cpus = 8\n",
    "plasma_store_size = 130*(1024**3)\n",
    "heap_memory = 230*(1024**3)\n",
    "# os.environ[\"MODIN_CPUS\"] = str(n_cpus)\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"\n",
    "os.environ[\"MODIN_NPARTITIONS\"] = \"30\"\n",
    "os.environ[\"MODIN_RANGE_PARTITIONING\"] = \"True\"\n",
    "# os.environ[\"MODIN_MEMORY\"] = str(plasma_store_size)\n",
    "ray.init(num_cpus =30,ignore_reinit_error=True, object_store_memory=plasma_store_size,_memory=heap_memory)\n",
    "# print(ray.cluster_resources())\n",
    "import modin.pandas as mpd\n",
    "from modin import config as cfg\n",
    "print(vars(cfg))\n",
    "NEPTUNE_MODE=\"sync\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export MODIN_CPUS=2\n",
    "import neptune\n",
    "import os\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"tom.touati/web-segmentation\",  # replace with your project\n",
    "    api_token=os.environ[\"NEPTUNE_API_TOKEN\"],\n",
    "    # name=\"Activity-Based Features\",\n",
    "    capture_stdout=True,\n",
    "    capture_stderr=True,\n",
    "    capture_hardware_metrics=True,\n",
    "    tags=[\"time-based-models\", \"activity-based-features\"],\n",
    "    description=\"User activity patterns analysis\",\n",
    "    mode=NEPTUNE_MODE\n",
    ")\n",
    "import neptune\n",
    "\n",
    "# Initialize Neptune run\n",
    "\n",
    "# Log parameters\n",
    "params = {}\n",
    "\n",
    "    # \"general_user_time_bin\": {\n",
    "    #     \"should_run\": True,\n",
    "    #     \"bin_hours\": 3\n",
    "    # },\n",
    "\n",
    "\n",
    "\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "# Log notebook\n",
    "run[\"notebook\"].upload(\"/home/tom.touati/mafat-challenge/code/time_based_model.ipynb\")\n",
    "\n",
    "# Log metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "  # Modin will use Ray\n",
    "# ray.init()\n",
    "# NPartitions.put(16)\n",
    "def load_data_from_db(con,domain_cls=False,only_domain=False):\n",
    "    try:\n",
    "        # First get 1000 random Device_IDs\n",
    "        # selective_device_ids_query = \"\"\"\n",
    "        # WITH random_devices AS (\n",
    "        #     SELECT DISTINCT Device_ID \n",
    "        #     FROM data \n",
    "        #     LIMIT 1000\n",
    "        # )\n",
    "        # SELECT Domain_Name, Device_ID, Target,Datetime\n",
    "        # FROM data \n",
    "        # WHERE Device_ID IN (SELECT Device_ID FROM random_devices)\n",
    "        # AND Domain_Name != 1732927\n",
    "        # \"\"\"\n",
    "        additional_query = \"\"\n",
    "        if domain_cls:\n",
    "            additional_query = \",Domain_cls1,Domain_cls2,Domain_cls3,Domain_cls4\"\n",
    "        device_ids_query = f\"\"\"SELECT Domain_Name, Device_ID, Target,Datetime{additional_query} from data\"\"\"\n",
    "        \n",
    "        if only_domain:\n",
    "            device_ids_query = f\"\"\"SELECT Domain_Name{additional_query} from data\"\"\"\n",
    "        # WHERE Domain_Name != 1732927 \"\"\"\n",
    "        df = mpd.read_sql(device_ids_query, con\n",
    "                         )._repartition()\n",
    "        df = df[df['Domain_Name'] != 1732927]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from db\n",
    "freeze_support()\n",
    "dbfile = '../../data/training_set.db'\n",
    "\n",
    "conn = ModinDatabaseConnection('sqlalchemy', f'sqlite:///{dbfile}')\n",
    "\n",
    "# Can use get_connection to get underlying sqlalchemy engine\n",
    "conn.get_connection()\n",
    "db_df = load_data_from_db(conn)\n",
    "print(db_df.head())\n",
    "del conn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_df['Datetime'] = mpd.to_datetime(db_df['Datetime'])\n",
    "db_df.set_index('Datetime', inplace=True)\n",
    "db_df = db_df.astype( {'Domain_Name': 'uint32', 'Device_ID': 'uint32', 'Target': 'uint8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "import matplotlib.pyplot as plt\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test_devices(device_target_df, test_size=0.2, random_state=43):    \n",
    "    # Perform stratified split on device IDs\n",
    "    train_device_ids, test_device_ids = train_test_split(\n",
    "        device_target_df['Device_ID'],\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=device_target_df['Target']\n",
    "    )\n",
    "    return train_device_ids, test_device_ids\n",
    "\n",
    "def get_initial_train_data(db_df, test_size=0.2, random_state=42, min_domain_devices=10,n_devices_hist=False):\n",
    "    device_targets = db_df.groupby(\"Device_ID\")[\"Target\"].first().reset_index()\n",
    "    train_devices, test_device_ids = get_train_test_devices(device_targets,test_size=test_size,random_state=random_state)\n",
    "    train_df = db_df[db_df[\"Device_ID\"].isin(train_devices)]\n",
    "    devices_per_domain = train_df.groupby(\"Domain_Name\")[\"Device_ID\"].nunique()\n",
    "    \n",
    "    domain_mask = devices_per_domain>min_domain_devices\n",
    "    print(f\"Percentage of domains with more than {min_domain_devices} devices: {domain_mask.mean()*100:.2f}%\")\n",
    "    devices_per_domain = devices_per_domain[domain_mask]\n",
    "    if n_devices_hist:\n",
    "        hist = devices_per_domain.hist()\n",
    "        run[\"plots/domain_devices_hist\"].upload(neptune.types.File.as_image(hist.figure))\n",
    "        plt.show()\n",
    "    train_df = train_df[train_df[\"Domain_Name\"].isin(devices_per_domain.index)]\n",
    "    return train_df,train_devices,test_device_ids, device_targets, devices_per_domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update({\"training_data\":{\n",
    "        \"min_domain_devices\": 10,\n",
    "        \"n_devices_hist\":True,\n",
    "        \"test_size\": 0.2,\n",
    "        \"random_state\": 42\n",
    "    }})\n",
    "train_df,train_devices,test_device_ids, device_targets,devices_per_valid_domain = get_initial_train_data(db_df,**params[\"training_data\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile timeseries_processing.py\n",
    "# preprocess timeseries\n",
    "from functools import partial\n",
    "def process_activity_timeseries(domain_df,bin_hours=6,gaussian_filter=True,n_days_each_side=3,std=1.5,drop_na=True,drop_zeros=False):\n",
    "    activity_per_3h = domain_df[[\"Device_ID\"]].resample(f'{str(bin_hours)}h').nunique()\n",
    "    activity_per_3h.rename(columns={\"Device_ID\":\"Activity\"},inplace=True)\n",
    "    # activity_per_3h = activity_per_3h.to_frame()\n",
    "\n",
    "    gaussian_window_hours = int(n_days_each_side*24/bin_hours*2) # n_days_each_side * 24h / 3h_per_bin * 2 sides\n",
    "    if gaussian_filter:\n",
    "        activity_per_3h = activity_per_3h.rolling(window=gaussian_window_hours, win_type='gaussian',center=True,min_periods=1,closed=\"both\").mean(std=std)\n",
    "    if drop_na:\n",
    "        activity_per_3h.dropna(inplace=True)\n",
    "    if drop_zeros:\n",
    "        activity_per_3h = activity_per_3h[activity_per_3h[\"Activity\"]!=0]\n",
    "    return activity_per_3h.round().astype(int)\n",
    "\n",
    "def get_domain_activity_timeseries(train_df,domain_ts_kwargs):\n",
    "    process_domain_timeseries = partial(process_activity_timeseries,**domain_ts_kwargs)\n",
    "    process_domain_timeseries.__name__ =process_activity_timeseries.__name__\n",
    "    domain_timeseries = train_df[[\"Domain_Name\",\"Target\",\"Device_ID\"]].groupby([\"Domain_Name\",\"Target\"]).apply(process_domain_timeseries)\n",
    "    \n",
    "    domain_timeseries = domain_timeseries\n",
    "    domain_timeseries[\"activity_fraction\"] = domain_timeseries.groupby([\"Domain_Name\", \"Target\"]).transform(lambda x: x/x.sum())\n",
    "    # Add the sum of activity as a new column\n",
    "    domain_activity = domain_timeseries.groupby([\"Domain_Name\", \"Target\"])[[\"Activity\"]].sum()\n",
    "\n",
    "    domain_activity = domain_activity.rename(columns={\"Activity\": \"target_domain_activity\"})\n",
    "    # Merge the results\n",
    "    domain_timeseries = domain_timeseries.merge(domain_activity, left_index=True, right_index=True)\n",
    "    # Reset index to get Target as a column, then pivot to get Target as columns\n",
    "    pivot_fraction_ts = domain_timeseries.reset_index().pivot(\n",
    "        index=['Datetime', 'Domain_Name'],\n",
    "        columns='Target'\n",
    "    ).fillna(0)\n",
    "    pivot_fraction_ts.columns = [f'{col[0]}_{col[1]}' for col in pivot_fraction_ts.columns]\n",
    "    return pivot_fraction_ts\n",
    "def get_user_activity_timeseries(db_df,user_ts_kwargs):\n",
    "    process_user_timeseries = partial(process_activity_timeseries,**user_ts_kwargs)\n",
    "    process_user_timeseries.__name__ =process_activity_timeseries.__name__\n",
    "    user_timeseries = db_df[[\"Domain_Name\",\"Device_ID\"]].groupby([\"Domain_Name\",\"Device_ID\"]).apply(process_user_timeseries)\n",
    "    # user_timeseries.index = mpd.MultiIndex.from_tuples(user_timeseries.index.to_list(),names=[\"Domain_Name\",\"Device_ID\",\"Datetime\"])\n",
    "    return user_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df._repartition()\n",
    "params.update({\"domain_activity_timeseries\": {\n",
    "        \"bin_hours\": 6,\n",
    "        \"gaussian_filter\": True, \n",
    "        \"n_days_each_side\": 7,\n",
    "        \"std\": 1.5,\n",
    "        \"drop_na\": False,\n",
    "        \"drop_zeros\": True\n",
    "    }})\n",
    "domain_activity_timeseries = get_domain_activity_timeseries(\n",
    "    train_df._repartition(), params[\"domain_activity_timeseries\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_domain_activity = domain_activity_timeseries.reset_index(\"Datetime\").loc[best_features].set_index(\"Datetime\",append=True)\n",
    "params.update({\"domain_activity_timeseries\": {\n",
    "        \"bin_hours\": 6,\n",
    "        \"gaussian_filter\": True, \n",
    "        \"n_days_each_side\": 7,\n",
    "        \"std\": 1.5,\n",
    "        \"drop_na\": False,\n",
    "        \"drop_zeros\": True\n",
    "    }})\n",
    "\n",
    "params.update({\"user_activity_timeseries\": {\n",
    "        \"bin_hours\": 6,\n",
    "        \"gaussian_filter\": True, \n",
    "        \"n_days_each_side\": 3,\n",
    "        \"std\": 1.5,\n",
    "        \"drop_na\": True,\n",
    "        \"drop_zeros\": False\n",
    "    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params.update({\"user_activity_timeseries\": {\n",
    "        \"bin_hours\": 6,\n",
    "        \"gaussian_filter\": True, \n",
    "        \"n_days_each_side\": 3,\n",
    "        \"std\": 1.5,\n",
    "        \"drop_na\": True,\n",
    "        \"drop_zeros\": False\n",
    "    }})\n",
    "user_activity_timeseries = get_user_activity_timeseries(\n",
    "    db_df.loc[db_df[\"Domain_Name\"].isin(devices_per_valid_domain.index)], params[\"user_activity_timeseries\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import ctypes\n",
    "import sys\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"\n",
    "    Force cleanup of memory by:\n",
    "    1. Running garbage collection\n",
    "    2. Attempting to release memory back to OS\n",
    "    \"\"\"\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Attempt to release memory back to the OS\n",
    "    if sys.platform.startswith('linux'):\n",
    "        libc = ctypes.CDLL('libc.so.6')\n",
    "        # MALLOC_TRIM(0) releases memory back to OS if possible\n",
    "        libc.malloc_trim(0)\n",
    "\n",
    "# Clean up memory\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "def class_probability_score(active, p_active_given_a, p_active_given_b, prior_a=0.5, total_users=100):\n",
    "    \"\"\"\n",
    "    Calculate class probability score with vectorized operations\n",
    "    \n",
    "    Args:\n",
    "        active: Boolean indicating if user was active\n",
    "        p_active_given_a: Probability of activity given class A (0)\n",
    "        p_active_given_b: Probability of activity given class B (1)\n",
    "        prior_a: Prior probability for class A\n",
    "        total_users: Total number of users for confidence calculation\n",
    "    \"\"\"\n",
    "    # Use numpy for vectorized operations\n",
    "    likelihood_a = np.where(active, p_active_given_a, 1 - p_active_given_a)\n",
    "    likelihood_b = np.where(active, p_active_given_b, 1 - p_active_given_b)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    evidence = (likelihood_a * prior_a + likelihood_b * (1 - prior_a))\n",
    "    posterior_a = (likelihood_a * prior_a) / evidence\n",
    "\n",
    "    return posterior_a #* confidence_factor\n",
    "\n",
    "def get_user_domain_scores(domain_activity_timeseries,user_activity_timeseries):\n",
    "    merged_timeseries_df = domain_activity_timeseries.reset_index().merge(\n",
    "        user_activity_timeseries.reset_index(), how=\"left\", on=[\"Domain_Name\", \"Datetime\"]\n",
    "    ).set_index([\"Datetime\", \"Domain_Name\", \"Device_ID\"])\n",
    "\n",
    "    merged_timeseries_df[\"bin_activity\"] = merged_timeseries_df[\"Activity_0\"]+merged_timeseries_df[\"Activity_1\"]\n",
    "    merged_timeseries_df[\"total_activity\"] = (merged_timeseries_df[\"target_domain_activity_0\"]+merged_timeseries_df[\"target_domain_activity_1\"])\n",
    "    merged_timeseries_df[\"relative_0_activity\"] = merged_timeseries_df[\"target_domain_activity_0\"]/merged_timeseries_df[\"total_activity\"]\n",
    "    merged_timeseries_df[\"score\"]=class_probability_score(merged_timeseries_df[\"Activity\"], merged_timeseries_df[\"activity_fraction_0\"], merged_timeseries_df[\"activity_fraction_1\"], prior_a=merged_timeseries_df[\"relative_0_activity\"], total_users=merged_timeseries_df[\"bin_activity\"])\n",
    "    merged_timeseries_df[\"relative_bin_activity\"] = merged_timeseries_df[\"bin_activity\"]/merged_timeseries_df[\"total_activity\"]\n",
    "    merged_timeseries_df[\"weighted_score\"] = (merged_timeseries_df[\"score\"])*(merged_timeseries_df[\"relative_bin_activity\"])#np.log(1+merged_df[\"bin_activity\"]).astype(int))\n",
    "    \n",
    "    #check (weighted_score-0.5)/std(weighted_score)/sqrt(total_activity)\n",
    "    final_scores = merged_timeseries_df.groupby([\"Device_ID\",\"Domain_Name\"])[\"weighted_score\"].sum()\n",
    "    \n",
    "    final_scores_pivot = final_scores.to_frame().reset_index().pivot(index=\"Device_ID\",columns=\"Domain_Name\")\n",
    "    return final_scores_pivot\n",
    "def get_domain_usage_proportion(db_df):\n",
    "    return db_df.groupby(\"Device_ID\")[\"Domain_Name\"].value_counts(normalize=True).unstack(fill_value=0).astype(np.float32)\n",
    "    \n",
    "def min_max_scale_all_values(df,train_devices,per_column=False):\n",
    "    # Create MinMaxScaler and fit on training data\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    train_data = df.loc[train_devices]\n",
    "    scaler.fit(train_data if per_column else train_data.values.reshape(-1,1))\n",
    "\n",
    "    # Transform all data using fitted scaler\n",
    "    df.iloc[:,:] = scaler.transform(df if per_column else df.values.reshape(-1,1)).reshape(df.shape)\n",
    "\n",
    "    # Save scaler parameters as JSON\n",
    "    scaler_params = {\n",
    "        \"min_\": float(scaler.min_[0]),  # Convert to native Python float\n",
    "        \"scale_\": float(scaler.scale_[0]),\n",
    "        \"data_min_\": float(scaler.data_min_[0]),\n",
    "        \"data_max_\": float(scaler.data_max_[0]),\n",
    "        \"data_range_\": float(scaler.data_range_[0]),\n",
    "        \"feature_range\": list(scaler.feature_range)  # Convert tuple to list for JSON\n",
    "    }\n",
    "    return scaler_params\n",
    "    # with open('submission/minmax_scaler.json', 'w') as f:\n",
    "    #     json.dump(scaler_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_usage_proportion = get_domain_usage_proportion(db_df)\n",
    "domain_usage_proportion = ((domain_usage_proportion.T)/domain_usage_proportion.T.max()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_scores_pivot=get_user_domain_scores(domain_activity_timeseries,user_activity_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scale_all_values(final_scores_pivot,train_devices,per_column=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_pivot.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_pivot.isna().sum().sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_pivot = (final_scores_pivot-final_scores_pivot.stack().mean())/final_scores_pivot.stack().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "final_scores_pivot.stack().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = device_targets.set_index(\"Device_ID\").join(weighted_final_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scale_all_values(weighted_final_scores,train_devices,per_column=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "weighted_final_scores = ((weighted_final_scores-weighted_final_scores.stack().mean())/weighted_final_scores.stack().std())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "target_features.set_index(\"Target\")[[int(x) for x in best_features if x.isnumeric()]].stack().groupby(\"Target\").mean().plot(kind=\"bar\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_final_scores.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(domain_usage_proportion==1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((domain_usage_proportion.T)/domain_usage_proportion.T.max()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_usage_proportion.stack().hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_pivot = (final_scores_pivot-final_scores_pivot.mean().mean())/final_scores_pivot.stack().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_final_scores = final_scores_pivot.mul(domain_usage_proportion[final_scores_pivot.columns]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_weights = device_targets.set_index(\"Device_ID\").join(weighted_final_scores)\n",
    "targeted_weights=targeted_weights.melt(id_vars=\"Target\",var_name=\"Domain_Name\",value_name=\"Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target, g in targeted_weights.groupby(\"Target\"):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     g = g.sort_values(\"Weight\")\n",
    "#     mean = g.mean()\n",
    "#     perc_25 = g.quantile(0.25)\n",
    "#     perc_75 = g.quantile(0.75)\n",
    "\n",
    "#     plt.scatter(target, mean, label=f'Target {target}')\n",
    "#     plt.fill_between(target, perc_25, perc_75, alpha=0.2)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_final_scores.stack().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_final_scores.stack().hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_usage_proportion[final_scores_pivot.columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer# , IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "def impute_missing_values(final_scores_pivot,train_device_ids):\n",
    "    # Use SoftImpute to fill missing values\n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "    imputer.fit(final_scores_pivot.loc[train_device_ids])\n",
    "    imputed_scores = imputer.transform(final_scores_pivot)\n",
    "    # imputer = AlternatingLeastSquares(factors=10, regularization=0.01, iterations=10,random_state=0)\n",
    "    # # imputer = MissForest(max_depth=6,max_features=0.8, random_state=0)\n",
    "    # imputer.fit( user_items = csr_matrix(final_scores_pivot.loc[train_device_ids].values))\n",
    "    \n",
    "    # imputed_scores = imputer.recommend_all(csr_matrix(final_scores_pivot.values))\n",
    "    return imputed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scale_all_values(final_scores_pivot,train_devices,per_column=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# baseline features\n",
    "def get_active_days_per_user(user_domain_ts):\n",
    "    \"\"\"\n",
    "    Calculate the number of unique days each user had any activity.\n",
    "\n",
    "    Args:\n",
    "        user_domain_ts: MultiIndex Series with levels [Domain_Name, Device_ID, Datetime]\n",
    "\n",
    "    Returns:\n",
    "        Series with index Device_ID and values being number of unique active days\n",
    "    \"\"\"\n",
    "    # Reset index to get Datetime as a column\n",
    "    df = user_domain_ts.reset_index()\n",
    "\n",
    "    # Convert Datetime to date (removing time component)\n",
    "    df['Date'] = df['Datetime'].dt.date\n",
    "\n",
    "    # Group by Device_ID and count unique dates where Activity > 0\n",
    "    active_days = df[df['Activity'] > 0].groupby('Device_ID')['Date'].nunique()\n",
    "\n",
    "    active_days = active_days.astype(int)\n",
    "    active_days.name = \"Active_Days\"\n",
    "    active_days = (active_days-active_days.min()\n",
    "                   ) / (active_days.max()-active_days.min())*2-1\n",
    "    return active_days\n",
    "\n",
    "\n",
    "def get_activity_per_time_bin(df, bin_hours=3):\n",
    "    # Convert datetime to time only\n",
    "    # time_index = db_df.index.to_series().dt.time\n",
    "    # df[\"time\"] = time_index\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"time\"] = db_df.index.to_series().dt.hour.astype(int)//bin_hours\n",
    "    df_copy[\"day_part_activity\"] = 0\n",
    "    activity_per_time_range = df_copy[[\"Device_ID\", \"time\", \"day_part_activity\"]].groupby(\n",
    "        [\"Device_ID\", \"time\"]).count()\n",
    "    activity_per_time_range[\"activity_fraction\"] = activity_per_time_range.groupby(\"Device_ID\").apply(lambda x: x/x.sum()).values\n",
    "    activity_per_time_range = activity_per_time_range[[\"activity_fraction\"]].reset_index()\n",
    "    activity_per_time_range = activity_per_time_range.pivot(index=\"Device_ID\",columns=\"time\",values=\"activity_fraction\")\n",
    "    activity_per_time_range.columns = [f\"time_{col}\" for col in activity_per_time_range.columns]\n",
    "    activity_per_time_range = (activity_per_time_range-activity_per_time_range.stack().min())/(activity_per_time_range.stack().max()-activity_per_time_range.stack().min())*2-1\n",
    "    activity_per_time_range = activity_per_time_range.fillna(0)\n",
    "    return activity_per_time_range  # .round().astype(int)\n",
    "def get_device_domain_pca(user_activity_timeseries, n_components=100):\n",
    "    # Calculate total entries per domain for each device\n",
    "    domain_entries = user_activity_timeseries.reset_index()[['Device_ID', 'Domain_Name','Activity']].groupby(['Device_ID', 'Domain_Name'])['Activity'].sum()\n",
    "    domain_entries_pivot = domain_entries.unstack(fill_value=0)\n",
    "    # domain_entries_pivot = domain_entries_pivot/domain_entries_pivot.sum(axis=1)\n",
    "    # Normalize the data\n",
    "    # normalized_data = (domain_entries_pivot - domain_entries_pivot.min().min()) / (domain_entries_pivot.max().max() - domain_entries_pivot.min().min())\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(domain_entries_pivot.fillna(0))\n",
    "    # Print explained variance ratio\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance ratio: {explained_variance.sum():.3f}\")\n",
    "    # Create DataFrame with PCA results\n",
    "    pca_df = mpd.DataFrame(\n",
    "        pca_result,\n",
    "        index=domain_entries_pivot.index,\n",
    "        columns=[f'pca_domain_{i}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from db\n",
    "\n",
    "def get_cls_proportion(df):\n",
    "    cols = [\"Domain_cls1\",\"Domain_cls2\",\"Domain_cls3\",\"Domain_cls4\"]\n",
    "    df = df.groupby(\"Device_ID\")[cols].apply(lambda x: df.stack().value_counts(normalize=True).T.fillna(0).to_frame().T)\n",
    "\n",
    "    \n",
    "    df.columns = [f\"cls_{col}\" for col in df.columns]\n",
    "    df.rename({\"cls_Device_ID\":\"Device_ID\"},axis=1,inplace=True)\n",
    "    df.index = df.index.droplevel(-1)\n",
    "    return df\n",
    "def get_cls_data():\n",
    "    \"\"\"\n",
    "    Feature engeinering: For each Device_ID calculate the proportions of all the domain_cls he entered.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conn: connection\n",
    "        A connection object to the database.\n",
    "    device_list : list\n",
    "        A list of Device_IDs to calculate their proportions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        A dataframe with the proportions for each Device_IDs and Domain_cls.\n",
    "    \"\"\"\n",
    "    freeze_support()\n",
    "    dbfile = '../../data/training_set.db'\n",
    "\n",
    "    conn = ModinDatabaseConnection('sqlalchemy', f'sqlite:///{dbfile}')\n",
    "\n",
    "    # Can use get_connection to get underlying sqlalchemy engine\n",
    "    conn.get_connection()\n",
    "    sql = '''SELECT\n",
    "                    Device_ID,\n",
    "                    Domain_Name,\n",
    "                    Domain_cls1,\n",
    "                    Domain_cls2,\n",
    "                    Domain_cls3,\n",
    "                    Domain_cls4\n",
    "                    from data\n",
    "                    where Domain_Name != 1732927 and Domain_cls1 != 0 and Domain_cls2 != 0 and Domain_cls3 != 0 and Domain_cls4 != 0\n",
    "                    '''\n",
    "\n",
    "    df = mpd.read_sql(sql,conn, columns = ['Device_ID','Domain_cls', 'proportion'])\n",
    "    \n",
    "    return df\n",
    "cls_data = get_cls_data()\n",
    "cls_proportion = get_cls_proportion(cls_data)\n",
    "del cls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain_best_features = [int(x) for x in best_features if x.isnumeric()]\n",
    "# final_scores_pivot.loc[:,domain_best_features] = impute_missing_values(final_scores_pivot.loc[:,domain_best_features],train_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = device_targets.set_index(\"Device_ID\").join(weighted_final_scores)\n",
    "final_features = final_features.join(cls_proportion,how=\"left\")\n",
    "final_features = final_features.join(psd_df,how=\"left\")\n",
    "# final_features = final_features.join(device_domain_PCA,how=\"left\")\n",
    "# if active_days is not None:\n",
    "#     final_features = final_features.join(active_days,how=\"left\")\n",
    "# if activity_per_time_range is not None:\n",
    "#     final_features = final_features.join(activity_per_time_range,how=\"left\")\n",
    "# final_features = final_features.fillna(0)\n",
    "# final_features.columns = [str(col) for col in final_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Get power spectra for training devices only\n",
    "train_psd = psd_df.loc[train_devices]\n",
    "\n",
    "# Create and fit scaler on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_psd)\n",
    "\n",
    "# Transform all data using fitted scaler\n",
    "psd_df.iloc[:,:] = scaler.transform(psd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def prepare_model_data(final_features,train_devices,test_device_ids):\n",
    "    X_train = final_features[final_features.index.isin(train_devices)].drop('Target', axis=1)\n",
    "    y_train = final_features[final_features.index.isin(train_devices)]['Target']\n",
    "\n",
    "    X_test = final_features[final_features.index.isin(test_device_ids)].drop('Target', axis=1)\n",
    "    y_test = final_features[final_features.index.isin(test_device_ids)]['Target']\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "def train_model(X_train,y_train,X_test=None,y_test=None,params = None):\n",
    "    xgb_reg = xgboost.XGBRegressor(**params ,eval_metric =roc_auc_score)\n",
    "    selector = RFE(xgb_reg, n_features_to_select=1000, step=20000)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    best_features = list(X_train.columns[selector.support_])\n",
    "    if X_test is not None:\n",
    "        test_prediction = selector.estimator_.predict(X_test[best_features])\n",
    "        test_auc =round(roc_auc_score(y_test,test_prediction), 3)\n",
    "        return test_auc,selector, best_features,y_test,test_prediction\n",
    "    return None,selector, best_features, None,None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import neptune\n",
    "\n",
    "params.update({\n",
    "    \"feature_selection\": {\n",
    "        \"n_features\": 1000,\n",
    "        \"step\": 20000\n",
    "    },\n",
    "    \"model\": dict(random_state=0, subsample=0.8, colsample_bytree=0.6, learning_rate= 0.1,\n",
    "                               n_estimators= 250, max_depth=6, objective ='binary:logistic',reg_lambda = 1.3 ),\n",
    "    \"no-normalization-finalscores\":True})\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"tom.touati/web-segmentation\",  # replace with your project\n",
    "    api_token=os.environ[\"NEPTUNE_API_TOKEN\"],\n",
    "    # name=\"Activity-Based Features\",\n",
    "    capture_stdout=True,\n",
    "    capture_stderr=True,\n",
    "    capture_hardware_metrics=True,\n",
    "    tags=[\"time-based-models\", \"activity-based-features\"],\n",
    "    description=\"User activity patterns analysis\",\n",
    "    mode=NEPTUNE_MODE\n",
    ")\n",
    "run[\"parameters\"] = params\n",
    "run[\"notebook\"].upload(\"/home/tom.touati/mafat-challenge/code/time_based_model.ipynb\")\n",
    "\n",
    "\n",
    "final_features.columns = [str(col) for col in final_features.columns]\n",
    "X_train,y_train,X_test,y_test = prepare_model_data(final_features,train_devices,test_device_ids)\n",
    "\n",
    "score,selector,best_features,y_test,test_prediction = train_model(X_train,y_train,X_test,y_test,params[\"model\"])\n",
    "print(f'The auc for validation set: {score}')\n",
    "# calculate confusion matrix relative to prediction\n",
    "\n",
    "\n",
    "run[\"metrics/roc_auc\"] = score\n",
    "run[\"metrics/selected_features\"] = str(best_features)\n",
    "run[\"metrics/feature_importances\"] = str(selector.estimator_.feature_importances_)\n",
    "run[\"metrics/feature_ranking\"] = str(selector.ranking_)\n",
    "run[\"metrics/feature_support\"] = str(selector.support_)\n",
    "# # Close the run\n",
    "\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = selector.estimator_.predict(X_train[best_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fft\n",
    "import numpy as np\n",
    "\n",
    "# total_user_activity = user_activity_timeseries.groupby([\"Device_ID\",\"Datetime\"]).sum()\n",
    "total_user_activity = total_user_activity.unstack()\n",
    "total_user_activity = total_user_activity.fillna(0)\n",
    "# Get power spectrum for each user's activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_activity.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spectrums = np.abs(fft.fft(total_user_activity.T.values))**2\n",
    "sample_d = 3*60*60\n",
    "freqs = fft.fftfreq(total_user_activity.shape[0],d=sample_d)\n",
    "power_spectrums.shape\n",
    "freq_mask = freqs>0\n",
    "power_spectrums = power_spectrums[:,freq_mask]\n",
    "freqs = freqs[freq_mask]\n",
    "# Convert to dataframe and normalize\n",
    "# power_spectrums_df = power_spectrums.to_frame('power_spectrum')\n",
    "# power_spectrums_df = (power_spectrums_df - power_spectrums_df.min()) / (power_spectrums_df.max() - power_spectrums_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_df = mpd.DataFrame(power_spectrums,index=total_user_activity.columns,columns=freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(freqs,power_spectrums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_activity.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred > 0.5,normalize=\"true\")\n",
    "\n",
    "# create confusion matrix heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create heatmap with percentage values\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='.1f', cmap='Blues')\n",
    "plt.title('Confusion Matrix (% of true labels)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, test_prediction > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_prediction > 0.5)\n",
    "\n",
    "# create confusion matrix heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create heatmap with percentage values\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='.1f', cmap='Blues')\n",
    "plt.title('Confusion Matrix (% of true labels)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = final_features.drop(\"Target\",axis=1)\n",
    "final_y = final_features[\"Target\"]\n",
    "full_data_model, full_data_features = train_model(final_x,final_y,params = params[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"submission/best_features.json\", \"w\") as fp:\n",
    "    json.dump(full_data_features, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"submission\",exist_ok=True)\n",
    "# with open(\"submission/XGB_model.json\", \"w\") as fp:\n",
    "full_data_model.estimator_.save_model('submission/XGB_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"submission/best_features.json\", \"w\") as fp:\n",
    "    json.dump(best_features, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.Series(best_features).to_csv(\"selected_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"submission\",exist_ok=True)\n",
    "# with open(\"submission/XGB_model.json\", \"w\") as fp:\n",
    "selector.estimator_.save_model('submission/XGB_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_activity_timeseries.reset_index()[domain_activity_timeseries.reset_index()[\"Domain_Name\"].isin([int(x) for x in best_features])].set_index([\"Datetime\",\"Domain_Name\"]).to_parquet(\"domain_activity_timeseries.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual feature filter\n",
    "# Create function to filter features based on mean values\n",
    "# def filter_low_mean_features(features_df, percentile=0.1):\n",
    "#     # Calculate absolute mean values for each feature\n",
    "#     abs_means = abs(features_df).mean()\n",
    "    \n",
    "#     # Calculate percentile threshold of absolute means\n",
    "#     threshold = abs_means.quantile(percentile)\n",
    "    \n",
    "#     # Get features with absolute means above threshold\n",
    "#     significant_features = abs_means[abs_means >= threshold].index\n",
    "    \n",
    "#     # Filter features\n",
    "\n",
    "#     return significant_features\n",
    "\n",
    "# Apply the filtering function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = np.array([int(x.replace(\"cls_\",\"\")) for x in best_features if x.startswith(\"cls_\")])\n",
    "test_df[[\"Domain_cls1\",\"Domain_cls2\",\"Domain_cls3\",\"Domain_cls4\"]]=np.stack([np.random.choice(cls,test_df.shape[0]) for i in range(4)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "class model:\n",
    "    def __init__(self,with_neptune=False):\n",
    "        '''\n",
    "        Init the model\n",
    "        '''\n",
    "        self.model = xgboost.XGBRegressor(\n",
    "            seed=0, \n",
    "            subsample=0.8, \n",
    "            colsample_bytree=0.8, \n",
    "            learning_rate=0.1,\n",
    "            n_estimators=150, \n",
    "            max_depth=6, \n",
    "            objective='binary:logistic',\n",
    "            eval_metric=roc_auc_score\n",
    "        )\n",
    "        self.domain_activity = None\n",
    "        self.user_activity = None\n",
    "        self.best_features = None\n",
    "        self.score_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    def get_cls_proportion(self,df):\n",
    "        cols=[\"Domain_cls1\",\"Domain_cls2\",\"Domain_cls3\",\"Domain_cls4\"]\n",
    "        df = df[cols]\n",
    "        df = df.stack()\n",
    "        df = df[df!=0]\n",
    "        df = df.value_counts(normalize=True).T.fillna(0)\n",
    "        df = df.to_frame().T\n",
    "        df.columns = [f\"cls_{col}\" for col in df.columns]\n",
    "        missing_cols = [x for x in self.best_features if x not in df.columns and x.startswith(\"cls_\")]\n",
    "        if len(missing_cols)>0:\n",
    "            df[missing_cols] = np.zeros((df.shape[0], len(missing_cols)))\n",
    "        return df\n",
    "    def process_activity_timeseries(self,domain_df,bin_hours=6,gaussian_filter=True,n_days_each_side=3,std=1.5,drop_na=True,drop_zeros=False):\n",
    "        activity_per_3h = domain_df[[\"Device_ID\"]].resample(f'{str(bin_hours)}h').nunique()\n",
    "        activity_per_3h.rename(columns={\"Device_ID\":\"Activity\"},inplace=True)\n",
    "        # activity_per_3h = activity_per_3h.to_frame()\n",
    "\n",
    "        gaussian_window_hours = int(n_days_each_side*24/bin_hours*2) # n_days_each_side * 24h / 3h_per_bin * 2 sides\n",
    "        if gaussian_filter:\n",
    "            activity_per_3h = activity_per_3h.rolling(window=gaussian_window_hours, win_type='gaussian',center=True,min_periods=1,closed=\"both\").mean(std=std)\n",
    "        if drop_na:\n",
    "            activity_per_3h.dropna(inplace=True)\n",
    "        if drop_zeros:\n",
    "            activity_per_3h = activity_per_3h[activity_per_3h[\"Activity\"]!=0]\n",
    "        return activity_per_3h.round().astype(int)\n",
    "\n",
    "    def class_probability_score(self,active, p_active_given_a, p_active_given_b, prior_a=0.5, total_users=100):\n",
    "        \"\"\"\n",
    "        Calculate class probability score with vectorized operations\n",
    "        \n",
    "        Args:\n",
    "            active: Boolean indicating if user was active\n",
    "            p_active_given_a: Probability of activity given class A (0)\n",
    "            p_active_given_b: Probability of activity given class B (1)\n",
    "            prior_a: Prior probability for class A\n",
    "            total_users: Total number of users for confidence calculation\n",
    "        \"\"\"\n",
    "        # Use numpy for vectorized operations\n",
    "        likelihood_a = np.where(active, p_active_given_a, 1 - p_active_given_a)\n",
    "        likelihood_b = np.where(active, p_active_given_b, 1 - p_active_given_b)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        evidence = (likelihood_a * prior_a + likelihood_b * (1 - prior_a))\n",
    "        posterior_a = (likelihood_a * prior_a) / evidence\n",
    "\n",
    "        return posterior_a #* confidence_factor\n",
    "\n",
    "\n",
    "    def get_user_domain_scores(self,user_activity_timeseries,domain_activity_timeseries):\n",
    "        merged_timeseries_df = domain_activity_timeseries.reset_index().merge(\n",
    "            user_activity_timeseries.reset_index(), how=\"inner\", on=[\"Domain_Name\", \"Datetime\"]\n",
    "        ).set_index([\"Datetime\", \"Domain_Name\", \"Device_ID\"])\n",
    "\n",
    "        merged_timeseries_df[\"bin_activity\"] = merged_timeseries_df[\"Activity_0\"]+merged_timeseries_df[\"Activity_1\"]\n",
    "        merged_timeseries_df[\"total_activity\"] = (merged_timeseries_df[\"target_domain_activity_0\"]+merged_timeseries_df[\"target_domain_activity_1\"])\n",
    "        merged_timeseries_df[\"relative_0_activity\"] = merged_timeseries_df[\"target_domain_activity_0\"]/merged_timeseries_df[\"total_activity\"]\n",
    "        merged_timeseries_df[\"score\"]=self.class_probability_score(merged_timeseries_df[\"Activity\"], merged_timeseries_df[\"activity_fraction_0\"], merged_timeseries_df[\"activity_fraction_1\"], \n",
    "                                                                   prior_a=merged_timeseries_df[\"relative_0_activity\"], total_users=merged_timeseries_df[\"bin_activity\"])\n",
    "        merged_timeseries_df[\"relative_bin_activity\"] = merged_timeseries_df[\"bin_activity\"]/merged_timeseries_df[\"total_activity\"]\n",
    "        merged_timeseries_df[\"weighted_score\"] = (merged_timeseries_df[\"score\"])*(merged_timeseries_df[\"bin_activity\"])\n",
    "        final_scores = merged_timeseries_df.groupby([\"Device_ID\",\"Domain_Name\"])[\"weighted_score\"].mean()\n",
    "        final_scores_pivot = final_scores.to_frame().reset_index().pivot(index=\"Device_ID\",columns=\"Domain_Name\").fillna(0)\n",
    "        final_scores_pivot = final_scores_pivot.droplevel(0, axis=1)\n",
    "        final_scores_pivot.columns = [str(col) for col in final_scores_pivot.columns]\n",
    "        missing_columns = [x for x in self.best_domains if x not in final_scores_pivot.columns]\n",
    "        final_scores_pivot[missing_columns] = np.zeros((final_scores_pivot.shape[0], len(missing_columns)))\n",
    "        final_scores_pivot = final_scores_pivot[self.best_domains]\n",
    "        return final_scores_pivot\n",
    "    def load_minmax_scaler(self,scaler_path):\n",
    "        '''\n",
    "        Load the MinMaxScaler from the given path\n",
    "        '''\n",
    "        with open(scaler_path, 'r') as f:\n",
    "            loaded_params = json.load(f)\n",
    "        self.score_scaler.min_ = np.array([loaded_params[\"min_\"]], dtype=np.float64)\n",
    "        self.score_scaler.scale_ = np.array([loaded_params[\"scale_\"]], dtype=np.float64)\n",
    "        self.score_scaler.data_min_ = np.array([loaded_params[\"data_min_\"]], dtype=np.float64)\n",
    "        self.score_scaler.data_max_ = np.array([loaded_params[\"data_max_\"]], dtype=np.float64)\n",
    "        self.score_scaler.data_range_ = np.array([loaded_params[\"data_range_\"]], dtype=np.float64)\n",
    "        self.score_scaler.feature_range = tuple(loaded_params[\"feature_range\"])\n",
    "    def load(self, dir_path):\n",
    "        '''\n",
    "        Load the trained model and domain activity data\n",
    "        '''\n",
    "        import os\n",
    "        import json\n",
    "\n",
    "        model_path = os.path.join(dir_path, 'XGB_model.json')\n",
    "        self.model.load_model(model_path)\n",
    "        best_features_path = os.path.join(dir_path, 'best_features.json')\n",
    "        with open(best_features_path, \"r\") as fp:\n",
    "            self.best_features = json.load(fp)\n",
    "        self.best_domains = [x for x in self.best_features if x.isnumeric()]\n",
    "        domain_activity_path = os.path.join(dir_path, 'best_domain_activity.parquet')\n",
    "        self.domain_activity = pd.read_parquet(domain_activity_path)\n",
    "        self.load_minmax_scaler(os.path.join(dir_path,'minmax_scaler.json'))\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the class probability for the input data\n",
    "        '''\n",
    "        # Process user timeseries\n",
    "        X = X.copy()\n",
    "        \n",
    "        if X['Datetime'].dtype == 'O':\n",
    "            X['Datetime'] = pd.to_datetime(X['Datetime'])\n",
    "        if \"Device_ID\" not in X.columns:\n",
    "            X[\"Device_ID\"] = 1\n",
    "        X.set_index(['Datetime'], inplace=True)\n",
    "        x_domains = X[X['Domain_Name'].isin([int(x) for x in self.best_domains])]\n",
    "        user_timeseries = x_domains[['Device_ID', 'Domain_Name']].groupby([\"Device_ID\",\"Domain_Name\"]).apply(lambda x :self.process_activity_timeseries(\n",
    "            x,\n",
    "            bin_hours=6,\n",
    "            gaussian_filter=True,\n",
    "            n_days_each_side=3,\n",
    "            std=1.5,\n",
    "            drop_na=True,\n",
    "            drop_zeros=False\n",
    "        ))\n",
    "        \n",
    "        # Get domain scores\n",
    "        final_scores = self.get_user_domain_scores(user_timeseries, self.domain_activity)\n",
    "        final_scores.iloc[:] = self.score_scaler.transform(final_scores.values.reshape(-1,1)).reshape(final_scores.shape)\n",
    "        cls_proportion = self.get_cls_proportion(X)\n",
    "        final_features = pd.concat([final_scores.reset_index(),cls_proportion.reset_index()],axis=1)[self.best_features]\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(final_features)\n",
    "        return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = db_df[db_df[\"Device_ID\"].isin(test_device_ids)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/tom.touati/mafat-challenge/code/submission/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import sys\n",
    "import os\n",
    "# X = test_df[test_df[\"Device_ID\"].isin(list(set(test_df[\"Device_ID\"])))]._to_pandas()#pd.read_csv('test_sample.csv')\n",
    "\n",
    "from code.submission.model import model\n",
    "import sys\n",
    "import os\n",
    "X=pd.read_csv('test_sample.csv')\n",
    "M = model()\n",
    "M.load('submission')\n",
    "Y_test=[]\n",
    "y_real=[]\n",
    "@ray.remote\n",
    "def ray_predict(m,x):\n",
    "    return m.predict(x)\n",
    "unique_Device_IDs = list(set(X.Device_ID))\n",
    "id_encountered = False\n",
    "for id in unique_Device_IDs:\n",
    "    X_test = X.loc[X['Device_ID'] == id]\n",
    "    # print(\"running device_id {}...\".format(id))\n",
    "    X_test.drop('Device_ID', axis=1, inplace=True)\n",
    "    print(M.predict(X_test))\n",
    "    # Y_test.append(ray_predict.remote(M,X_test))\n",
    "    # y_real.append(X_test['Target'].iloc[0])\n",
    "    # print(Y_test[-1], y_real)\n",
    "\n",
    "# print(f'Prediction: {Y_test[0]}')\n",
    "Y_test = [ray.get(y) for y in Y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Convert lists to numpy arrays if needed\n",
    "roc_auc = roc_auc_score(y_real, Y_test)\n",
    "print(f'ROC AUC Score: {roc_auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
