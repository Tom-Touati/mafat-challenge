{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresh Idea\n",
    "## separate one/zero activity of domains\n",
    "- replace zeros by minus one\n",
    "- calculate the class activity for 3 hours bins for each domain\n",
    "- calculate the user activity for gaussian around center of 3 hour bins\n",
    "- calculate the likelihood of the person being a 1/-1 in that time \n",
    "- add user general metrics including domain cls activity and usage patterns\n",
    "\n",
    "### questions\n",
    "- how to take into account times when the person used a website when others didnt?\n",
    "- how to give likelihood when the person didn't show any nearby activity?\n",
    "- what if he used a similar website at same time but more nich? \n",
    "- how to average the bins weighted by the significance of that bin?\n",
    "- how to give weight to the magnitude of number of users entering? probability of 1 with confidence\n",
    "- what about sparse websites?\n",
    "- how to not let times where there are no activity take a lot of weight?\n",
    "### enhancements\n",
    "- create graph embedding of urls\n",
    "- for each bin, calculate the metric per url\n",
    "- instead of only looking at the specific website, take into account websites with similar usages,\n",
    "  for example looking at same domain_cls usage in gaussian around bin, or looking at domain embeddings and looking at the activity in similar embeddings weighted by the distance in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 18:55:14,044\tWARNING services.py:2072 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1290870784 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-03-14 18:55:15,237\tINFO worker.py:1841 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Device_ID                   Datetime      URL  Domain_Name  Domain_cls1  \\\n",
      "0        124  2023-04-23 03:04:30+03:00     6466      2368671          755   \n",
      "1        124  2023-04-23 03:04:30+03:00  2245864      1792903            0   \n",
      "2        124  2023-04-23 03:04:30+03:00  1839478       107342          332   \n",
      "3        124  2023-04-23 03:14:50+03:00  1172090       107342          332   \n",
      "4        124  2023-04-23 03:14:50+03:00  1839478       107342          332   \n",
      "\n",
      "   Domain_cls2  Domain_cls3  Domain_cls4  Target  \n",
      "0          799            0            0       0  \n",
      "1            0            0            0       0  \n",
      "2            0            0            0       0  \n",
      "3            0            0            0       0  \n",
      "4            0            0            0       0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import freeze_support\n",
    "from modin.db_conn import ModinDatabaseConnection\n",
    "import modin.pandas as mpd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "import ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "def load_data_from_db(con):\n",
    "    try:\n",
    "        df = mpd.read_sql(\"SELECT * FROM data\", con)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "freeze_support()\n",
    "dbfile = '/workspace/data/mini_training_set.db'\n",
    "\n",
    "conn = ModinDatabaseConnection('sqlalchemy', f'sqlite:///{dbfile}')\n",
    "\n",
    "# Can use get_connection to get underlying sqlalchemy engine\n",
    "conn.get_connection()\n",
    "db_df = load_data_from_db(conn)\n",
    "print(db_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"23-04 to 18-05\"\n",
    "db_df = db_df[db_df[\"Domain_Name\"]!=1732927] # remove empty url\n",
    "db_df[\"Datetime\"] = mpd.to_datetime(db_df[\"Datetime\"])\n",
    "db_df.set_index(\"Datetime\",inplace=True)\n",
    "# db_df.groupby(\"Device_ID\").apply(lambda x: (x-x[\"Datetime\"].min()).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "def get_train_test_devices(device_target_df, test_size=0.2, random_state=42):    \n",
    "    # Perform stratified split on device IDs\n",
    "    train_device_ids, test_device_ids = train_test_split(\n",
    "        device_target_df['Device_ID'],\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=device_target_df['Target']\n",
    "    )\n",
    "    return train_device_ids, test_device_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = db_df.groupby(\"Device_ID\").first().reset_index()\n",
    "train_devices, test_device_ids = get_train_test_devices(devices)\n",
    "train_db_df = db_df[db_df[\"Device_ID\"].isin(train_devices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_per_domain = train_db_df.groupby(\"Domain_Name\")[\"Device_ID\"].nunique()\n",
    "domains = devices_per_domain[devices_per_domain>10].index\n",
    "train_db_df = train_db_df[train_db_df[\"Domain_Name\"].isin(domains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess timeseries\n",
    "def process_activity_timeseries(domain_df,bin_hours=6,gaussian_filter=True,n_days_each_side=3,std=1.5,drop_na=True,drop_zeros=False):\n",
    "    activity_per_3h = domain_df[\"Device_ID\"].resample(f'{str(bin_hours)}h').nunique()\n",
    "    gaussian_window_hours = int(n_days_each_side*24/bin_hours*2) # n_days_each_side * 24h / 3h_per_bin * 2 sides\n",
    "    if gaussian_filter:\n",
    "        activity_per_3h = activity_per_3h.rolling(window=gaussian_window_hours, win_type='gaussian',center=True,min_periods=1,closed=\"both\").mean(std=std)\n",
    "    if drop_na:\n",
    "        activity_per_3h.dropna(inplace=True)\n",
    "    if drop_zeros:\n",
    "        activity_per_3h = activity_per_3h[activity_per_3h!=0]\n",
    "    activity_per_3h.rename(\"Activity\",inplace=True)\n",
    "    return activity_per_3h.round().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "process_domain_timeseries = partial(process_activity_timeseries,gaussian_filter=True,n_days_each_side=3,std=1.5,drop_na=True,drop_zeros=False)\n",
    "process_domain_timeseries.__name__ =process_activity_timeseries.__name__\n",
    "domain_time_series = train_db_df.groupby([\"Domain_Name\",\"Target\"]).apply(process_domain_timeseries)\n",
    "# domain_no_target_time_series = train_db_df.groupby([\"Domain_Name\"]).apply(process_domain_timeseries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_domain_time_series = db_df.groupby([\"Device_ID\",\"Domain_Name\"]).apply(process_activity_timeseries)\n",
    "\n",
    "# Reset index to get all columns as regular columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_domain_time_series = user_domain_time_series.swaplevel(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: <function GroupBy.<lambda>> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate domain fractions and activity separately\n",
    "# First, calculate activity fraction\n",
    "domain_fraction_ts = domain_time_series.copy()\n",
    "domain_fraction_ts[\"activity_fraction\"] = domain_fraction_ts.groupby([\"Domain_Name\", \"Target\"]).transform(lambda x: x/x.sum())\n",
    "# Add the sum of activity as a new column\n",
    "domain_activity = domain_fraction_ts.groupby([\"Domain_Name\", \"Target\"])[[\"Activity\"]].sum()\n",
    "\n",
    "domain_activity = domain_activity.rename(columns={\"Activity\": \"target_domain_activity\"})\n",
    "# Merge the results\n",
    "domain_fraction_ts = domain_fraction_ts.merge(domain_activity, left_index=True, right_index=True)\n",
    "# Reset index to get Target as a column, then pivot to get Target as columns\n",
    "pivot_fraction_ts = domain_fraction_ts.reset_index().pivot(\n",
    "    index=['Datetime', 'Domain_Name'],\n",
    "    columns='Target'\n",
    ").fillna(0)\n",
    "pivot_fraction_ts.columns = [f'{col[0]}_{col[1]}' for col in pivot_fraction_ts.columns]\n",
    "# Rename columns for clarity\n",
    "# pivot_fraction_ts.columns = ['activity_0', 'activity_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pivot_fraction_ts.merge(user_domain_time_series.reset_index(),how=\"left\",on=[\"Domain_Name\",\"Datetime\"],)\n",
    "merged_df.set_index([\"Datetime\",\"Domain_Name\",\"Device_ID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "def class_probability_score(active, p_active_given_a, p_active_given_b, prior_a=0.5, total_users=100):\n",
    "    \"\"\"\n",
    "    Calculate class probability score with vectorized operations\n",
    "    \n",
    "    Args:\n",
    "        active: Boolean indicating if user was active\n",
    "        p_active_given_a: Probability of activity given class A (0)\n",
    "        p_active_given_b: Probability of activity given class B (1)\n",
    "        prior_a: Prior probability for class A\n",
    "        total_users: Total number of users for confidence calculation\n",
    "    \"\"\"\n",
    "    # Use numpy for vectorized operations\n",
    "    likelihood_a = np.where(active, p_active_given_a, 1 - p_active_given_a)\n",
    "    likelihood_b = np.where(active, p_active_given_b, 1 - p_active_given_b)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    evidence = (likelihood_a * prior_a + likelihood_b * (1 - prior_a))\n",
    "    posterior_a = (likelihood_a * prior_a) / evidence\n",
    "    \n",
    "    # Simplified confidence calculation\n",
    "    # alpha = 1 + posterior_a * total_users\n",
    "    # beta = 1 + (1 - posterior_a) * total_users\n",
    "    # ci_width = stats.beta.interval(0.95, alpha, beta)[1] - stats.beta.interval(0.95, alpha, beta)[0]\n",
    "    \n",
    "    # # Calculate final score\n",
    "    raw_score = 2 * posterior_a - 1\n",
    "    # confidence_factor = 1 - ci_width\n",
    "    \n",
    "    return raw_score #* confidence_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"bin_activity\"] = merged_df[\"Activity_0\"]+merged_df[\"Activity_1\"]\n",
    "merged_df[\"total_activity\"] = (merged_df[\"target_domain_activity_0\"]+merged_df[\"target_domain_activity_1\"])\n",
    "merged_df[\"relative_0_activity\"] = merged_df[\"target_domain_activity_0\"]/merged_df[\"total_activity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "merged_df[\"score\"]=class_probability_score(merged_df[\"Activity\"], merged_df[\"activity_fraction_0\"], merged_df[\"activity_fraction_1\"], prior_a=merged_df[\"relative_0_activity\"], total_users=merged_df[\"bin_activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n",
      "UserWarning: <function GroupBy.<lambda>> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "merged_df[\"weighted_score\"] = merged_df[\"score\"]*np.sqrt(merged_df[\"bin_activity\"])\n",
    "final_scores = merged_df.groupby([\"Device_ID\",\"Domain_Name\"])[\"weighted_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_scores_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDevice_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDomain_Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/pandas/dataframe.py:1510\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   1506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1507\u001b[0m         values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__constructor__(\n\u001b[0;32m-> 1510\u001b[0m     query_compiler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1513\u001b[0m )\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler_caster.py:157\u001b[0m, in \u001b[0;36mapply_argument_cast.<locals>.cast_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m cast_nested_args_to_current_qc_type(kwargs, current_qc)\n\u001b[1;32m    156\u001b[0m     args \u001b[38;5;241m=\u001b[39m cast_nested_args_to_current_qc_type(args, current_qc)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:4444\u001b[0m, in \u001b[0;36mPandasQueryCompiler.pivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   4441\u001b[0m     to_reindex \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m+\u001b[39m columns\n\u001b[1;32m   4443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 4444\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitem_column_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_reindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4446\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler_caster.py:157\u001b[0m, in \u001b[0;36mapply_argument_cast.<locals>.cast_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m cast_nested_args_to_current_qc_type(kwargs, current_qc)\n\u001b[1;32m    156\u001b[0m     args \u001b[38;5;241m=\u001b[39m cast_nested_args_to_current_qc_type(args, current_qc)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:3034\u001b[0m, in \u001b[0;36mPandasQueryCompiler.getitem_column_array\u001b[0;34m(self, key, numeric, ignore_order)\u001b[0m\n\u001b[1;32m   3032\u001b[0m         key_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(key)\n\u001b[1;32m   3033\u001b[0m         key \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m key_set]\n\u001b[0;32m-> 3034\u001b[0m     new_modin_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modin_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_2d_labels_or_positional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__constructor__(new_modin_frame, shape_hint\u001b[38;5;241m=\u001b[39mshape_hint)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/logging/logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[1;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/utils.py:753\u001b[0m, in \u001b[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m apply_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    752\u001b[0m         obj\u001b[38;5;241m.\u001b[39m_propagate_index_objs(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transpose:\n\u001b[1;32m    755\u001b[0m     result\u001b[38;5;241m.\u001b[39m_deferred_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred_index\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:1082\u001b[0m, in \u001b[0;36mPandasDataframe.take_2d_labels_or_positional\u001b[0;34m(self, row_labels, row_positions, col_labels, col_positions)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             col_positions[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_locs(label)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m         col_positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_2d_positional(row_positions, col_positions)\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6182\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6165\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[1;32m   6166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[1;32m   6180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 6182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6183\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m   6184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3953\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[1;32m   3950\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[1;32m   3951\u001b[0m     )\n\u001b[0;32m-> 3953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3980\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3978\u001b[0m         tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[0;32m-> 3980\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "File \u001b[0;32mindex.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7132\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "final_scores_pivot = final_scores.to_frame().pivot(index=\"Device_ID\",columns=\"Domain_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_pivot = final_scores.to_frame().reset_index().pivot(index=\"Device_ID\",columns=\"Domain_Name\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
