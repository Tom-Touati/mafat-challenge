{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The size of /dev/shm is too small (12884901888 bytes). The required size at least half of RAM (185619038208 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can can override the memory size for each Ray worker (in bytes) to the MODIN_MEMORY environment variable.\n",
      "2025-03-09 00:33:53,439\tINFO worker.py:1841 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Device_ID                   Datetime      URL  Domain_Name  Domain_cls1  \\\n",
      "0        124  2023-04-23 03:04:30+03:00     6466      2368671          755   \n",
      "1        124  2023-04-23 03:04:30+03:00  2245864      1792903            0   \n",
      "2        124  2023-04-23 03:04:30+03:00  1839478       107342          332   \n",
      "3        124  2023-04-23 03:14:50+03:00  1172090       107342          332   \n",
      "4        124  2023-04-23 03:14:50+03:00  1839478       107342          332   \n",
      "\n",
      "   Domain_cls2  Domain_cls3  Domain_cls4  Target  \n",
      "0          799            0            0       0  \n",
      "1            0            0            0       0  \n",
      "2            0            0            0       0  \n",
      "3            0            0            0       0  \n",
      "4            0            0            0       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 5659 MiB, 183 objects, write throughput 310 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from multiprocessing import freeze_support\n",
    "from modin.db_conn import ModinDatabaseConnection\n",
    "import modin.pandas as mpd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "def load_data_from_db(con):\n",
    "    try:\n",
    "        df = mpd.read_sql(\"SELECT * FROM data\", con)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "freeze_support()\n",
    "dbfile = '/workspace/code/train_data_for_competition/mini_training_set.db'\n",
    "\n",
    "conn = ModinDatabaseConnection('sqlalchemy', f'sqlite:///{dbfile}')\n",
    "\n",
    "# Can use get_connection to get underlying sqlalchemy engine\n",
    "conn.get_connection()\n",
    "db_df = load_data_from_db(conn)\n",
    "print(db_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2023-04-23 03:04:30+03:00\n",
       "1          2023-04-23 03:04:30+03:00\n",
       "2          2023-04-23 03:04:30+03:00\n",
       "3          2023-04-23 03:14:50+03:00\n",
       "4          2023-04-23 03:14:50+03:00\n",
       "                      ...           \n",
       "32248978   2023-05-13 21:26:02+03:00\n",
       "32248979   2023-05-13 21:26:03+03:00\n",
       "32248980   2023-05-13 21:32:33+03:00\n",
       "32248981   2023-05-13 21:32:38+03:00\n",
       "32248982   2023-05-13 21:32:43+03:00\n",
       "Name: Datetime, Length: 32248983, dtype: datetime64[ns, UTC+03:00]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"23-04 to 18-05\"\n",
    "db_df[\"Datetime\"] = mpd.to_datetime(db_df[\"Datetime\"])\n",
    "db_df[\"Datetime\"]\n",
    "# db_df.groupby(\"Device_ID\").apply(lambda x: (x-x[\"Datetime\"].min()).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile preprocessing.py\n",
    "def get_train_test_masks(domain_counts, test_size=0.2, random_state=42):\n",
    "    # Get unique device IDs and their corresponding targets\n",
    "    device_target_df = domain_counts.groupby('Device_ID')['Target'].first().reset_index()\n",
    "    \n",
    "    # Perform stratified split on device IDs\n",
    "    train_device_ids, test_device_ids = train_test_split(\n",
    "        device_target_df['Device_ID'],\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=device_target_df['Target']\n",
    "    )\n",
    "    \n",
    "    # Create mask for train/test split in domain_counts\n",
    "    train_mask = domain_counts['Device_ID'].isin(train_device_ids)\n",
    "    test_mask = domain_counts['Device_ID'].isin(test_device_ids)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Total devices: {len(device_target_df)}\")\n",
    "    print(f\"Train devices: {len(train_device_ids)}\")\n",
    "    print(f\"Test devices: {len(test_device_ids)}\")\n",
    "    print(f\"\\nTrain samples: {len(domain_counts[train_mask])}\")\n",
    "    print(f\"Test samples: {len(domain_counts[test_mask])}\")\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nTarget distribution in train set:\")\n",
    "    print(domain_counts[train_mask].groupby('Target').size() / len(domain_counts[train_mask]))\n",
    "    print(\"\\nTarget distribution in test set:\")\n",
    "    print(domain_counts[test_mask].groupby('Target').size() / len(domain_counts[test_mask]))\n",
    "    \n",
    "    return train_mask, test_mask\n",
    "\n",
    "def get_domain_counts(db_df, pivot=False):\n",
    "    domain_counts = db_df.groupby([\"Device_ID\",\"Domain_Name\",\"Target\"]).count()\n",
    "    domain_counts = domain_counts.reset_index()\n",
    "    domain_counts = domain_counts[[\"Device_ID\",\"Domain_Name\",\"Target\",\"Datetime\"]]\n",
    "    domain_counts.rename(columns={\"Datetime\":\"count\"}, inplace=True)\n",
    "    if pivot:\n",
    "        pivot_matrix = train_domain_counts.pivot(index='source', columns='target', values='count').fillna(0)\n",
    "        return pivot_matrix\n",
    "    return domain_counts\n",
    "def get_device_domain_fractions(domain_counts):\n",
    "    # Calculate total counts per device\n",
    "    device_totals = domain_counts.groupby('Device_ID')['count'].sum()\n",
    "    \n",
    "    # Calculate fractions by dividing each count by the device total\n",
    "    domain_fractions = domain_counts.copy()\n",
    "    domain_fractions['fraction'] = domain_fractions.apply(\n",
    "        lambda row: row['count'] / device_totals[row['Device_ID']], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return domain_fractions[['Device_ID', 'Domain_Name', 'Target', 'count', 'fraction']]\n",
    "def compute_domain_target_correlation(domain_counts):\n",
    "    # Group by Domain_Name and calculate mean Target and count\n",
    "    domain_stats = domain_counts.groupby('Domain_Name').agg({\n",
    "        'Target': 'mean',\n",
    "        'count': ['mean', 'std', 'count']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    domain_stats.columns = ['Domain_Name', 'target_mean', 'count_mean', 'count_std', 'n_devices']\n",
    "    \n",
    "    # Calculate correlation coefficient\n",
    "    # We only include domains that appear in multiple devices for statistical significance\n",
    "    significant_domains = domain_stats[domain_stats['n_devices'] > 1]\n",
    "    \n",
    "    # Calculate correlation and p-value\n",
    "    correlation = mpd.DataFrame({\n",
    "        'Domain_Name': significant_domains['Domain_Name'],\n",
    "        'target_correlation': significant_domains['target_mean'],\n",
    "        'avg_count': significant_domains['count_mean'],\n",
    "        'count_std': significant_domains['count_std'],\n",
    "        'n_devices': significant_domains['n_devices']\n",
    "    }).sort_values('target_correlation', ascending=False)\n",
    "    \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keep in mind that the best resolution will be achieved with a resolution of urls/chain of urls, not domains\")\n",
    "print(\"Cluster url walks\")\n",
    "print(\"I want to cluster urls/url walks from a given domain, to 3 categories\")\n",
    "print(\"positive correlation, zero correlation, negative correlation, to_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Basic features ( Domain Counts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_counts = get_domain_counts(db_df)\n",
    "del db_df\n",
    "pivot_matrix = domain_counts.pivot(index='Domain_Name', columns='Device_ID', values='count').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile correlation.py\n",
    "import numpy as np\n",
    "import ray\n",
    "@ray.remote\n",
    "def calculate_chunk_covariance(matrix_centered, start_idx, end_idx, columns):\n",
    "    # Calculate covariance for this chunk\n",
    "    chunk = matrix_centered[:, start_idx:end_idx]\n",
    "    chunk_cov = np.dot(chunk.T, matrix_centered) / (matrix_centered.shape[0] - 1)\n",
    "    return start_idx, end_idx, chunk_cov\n",
    "def compute_chunked_covariance(pivot_matrix, batch_size=2000):\n",
    "    # Convert to numpy array for faster computation\n",
    "    matrix_dense = pivot_matrix.to_numpy()\n",
    "    matrix_centered = matrix_dense - np.mean(matrix_dense, axis=0)\n",
    "\n",
    "    # Initialize parameters\n",
    "    n_cols = pivot_matrix.shape[1]\n",
    "    futures = []\n",
    "\n",
    "    # Submit tasks to Ray\n",
    "    for i in range(0, n_cols, batch_size):\n",
    "        batch_end = min(i + batch_size, n_cols)\n",
    "        futures.append(calculate_chunk_covariance.remote(matrix_centered, i, batch_end, pivot_matrix.columns))\n",
    "\n",
    "    # Collect results and combine\n",
    "    cov_chunks = []\n",
    "    for future in ray.get(futures):\n",
    "        start_idx, end_idx, chunk_cov = future\n",
    "        chunk_df = mpd.DataFrame(\n",
    "            chunk_cov,\n",
    "            index=pivot_matrix.columns[start_idx:end_idx],\n",
    "            columns=pivot_matrix.columns\n",
    "        )\n",
    "        cov_chunks.append(chunk_df)\n",
    "\n",
    "    # Combine all chunks\n",
    "    return mpd.concat(cov_chunks)\n",
    "def melt_covariance_matrix(covariance_matrix):\n",
    "    # Reset index to make it a column\n",
    "    melted = covariance_matrix.reset_index()\n",
    "    \n",
    "    # Melt the dataframe\n",
    "    melted = melted.melt(\n",
    "        id_vars=['Device_ID'],\n",
    "        var_name='target',\n",
    "        value_name='covariance'\n",
    "    )\n",
    "    \n",
    "    # Rename the 'index' column to 'source'\n",
    "    melted = melted.rename(columns={'Device_ID': 'source'})\n",
    "    \n",
    "    # Remove duplicate pairs (e.g., if A->B exists, remove B->A)\n",
    "    melted = melted[melted['source'] < melted['target']]\n",
    "    \n",
    "    # Remove rows where source equals target\n",
    "    melted = melted[melted['source'] != melted['target']]\n",
    "    \n",
    "    return melted.reset_index(drop=True)\n",
    "def filter_and_transform_covariance(melted_covariance, abs_threshold=0.03, log_threshold=10):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    result = melted_covariance\n",
    "    # Create corrected_cov column\n",
    "    result['corrected_cov'] = result['covariance'].copy()\n",
    "    \n",
    "    # Apply absolute threshold filter\n",
    "    result.loc[abs(result['corrected_cov']) < abs_threshold, 'corrected_cov'] = 0\n",
    "    \n",
    "    # Apply log transformation for values above log_threshold\n",
    "    high_vals_mask = abs(result['corrected_cov']) > log_threshold\n",
    "    result.loc[high_vals_mask, 'corrected_cov'] = result.loc[high_vals_mask, 'corrected_cov'].apply(\n",
    "        lambda x: np.log(abs(x)) * np.sign(x)\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Covariance/Correlation between domains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Device_ID</th>\n",
       "      <th>124</th>\n",
       "      <th>148</th>\n",
       "      <th>174</th>\n",
       "      <th>242</th>\n",
       "      <th>266</th>\n",
       "      <th>279</th>\n",
       "      <th>438</th>\n",
       "      <th>610</th>\n",
       "      <th>642</th>\n",
       "      <th>688</th>\n",
       "      <th>...</th>\n",
       "      <th>68884</th>\n",
       "      <th>68901</th>\n",
       "      <th>69158</th>\n",
       "      <th>69207</th>\n",
       "      <th>69449</th>\n",
       "      <th>69734</th>\n",
       "      <th>69811</th>\n",
       "      <th>69891</th>\n",
       "      <th>69910</th>\n",
       "      <th>69967</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Device_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2217.281915</td>\n",
       "      <td>802.394646</td>\n",
       "      <td>1644.651872</td>\n",
       "      <td>1572.076549</td>\n",
       "      <td>3225.376052</td>\n",
       "      <td>3065.667643</td>\n",
       "      <td>1002.485923</td>\n",
       "      <td>683.146132</td>\n",
       "      <td>216.999755</td>\n",
       "      <td>1254.956756</td>\n",
       "      <td>...</td>\n",
       "      <td>800.323922</td>\n",
       "      <td>4771.101910</td>\n",
       "      <td>378.968807</td>\n",
       "      <td>2087.473928</td>\n",
       "      <td>1000.364462</td>\n",
       "      <td>2428.496265</td>\n",
       "      <td>2402.145677</td>\n",
       "      <td>3399.952878</td>\n",
       "      <td>2989.466427</td>\n",
       "      <td>299.564781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>802.394646</td>\n",
       "      <td>2924.673893</td>\n",
       "      <td>49.767279</td>\n",
       "      <td>466.647514</td>\n",
       "      <td>1173.927569</td>\n",
       "      <td>1184.646557</td>\n",
       "      <td>634.057473</td>\n",
       "      <td>1503.602376</td>\n",
       "      <td>565.255376</td>\n",
       "      <td>737.214188</td>\n",
       "      <td>...</td>\n",
       "      <td>1710.937432</td>\n",
       "      <td>2264.690736</td>\n",
       "      <td>687.826019</td>\n",
       "      <td>621.614319</td>\n",
       "      <td>2295.599464</td>\n",
       "      <td>640.044255</td>\n",
       "      <td>657.977131</td>\n",
       "      <td>1102.128801</td>\n",
       "      <td>926.854822</td>\n",
       "      <td>585.848312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1644.651872</td>\n",
       "      <td>49.767279</td>\n",
       "      <td>11129.711224</td>\n",
       "      <td>3156.693064</td>\n",
       "      <td>10030.564785</td>\n",
       "      <td>3040.518387</td>\n",
       "      <td>628.336661</td>\n",
       "      <td>2863.376915</td>\n",
       "      <td>135.468064</td>\n",
       "      <td>589.841859</td>\n",
       "      <td>...</td>\n",
       "      <td>47.867393</td>\n",
       "      <td>9809.372937</td>\n",
       "      <td>117.110728</td>\n",
       "      <td>1045.156915</td>\n",
       "      <td>44.900549</td>\n",
       "      <td>2219.144555</td>\n",
       "      <td>1515.374675</td>\n",
       "      <td>9136.613955</td>\n",
       "      <td>2398.940668</td>\n",
       "      <td>2518.729878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1572.076549</td>\n",
       "      <td>466.647514</td>\n",
       "      <td>3156.693064</td>\n",
       "      <td>6644.670539</td>\n",
       "      <td>4928.050491</td>\n",
       "      <td>2362.428871</td>\n",
       "      <td>806.440792</td>\n",
       "      <td>1317.343908</td>\n",
       "      <td>170.283444</td>\n",
       "      <td>925.939938</td>\n",
       "      <td>...</td>\n",
       "      <td>540.884430</td>\n",
       "      <td>7242.237116</td>\n",
       "      <td>311.206679</td>\n",
       "      <td>1458.544681</td>\n",
       "      <td>663.470648</td>\n",
       "      <td>2016.197235</td>\n",
       "      <td>2220.289423</td>\n",
       "      <td>4770.031955</td>\n",
       "      <td>2554.675586</td>\n",
       "      <td>1059.015963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3225.376052</td>\n",
       "      <td>1173.927569</td>\n",
       "      <td>10030.564785</td>\n",
       "      <td>4928.050491</td>\n",
       "      <td>14551.003949</td>\n",
       "      <td>5003.606356</td>\n",
       "      <td>1717.602201</td>\n",
       "      <td>4112.996933</td>\n",
       "      <td>442.822017</td>\n",
       "      <td>1806.132237</td>\n",
       "      <td>...</td>\n",
       "      <td>1375.383078</td>\n",
       "      <td>14458.096890</td>\n",
       "      <td>791.676832</td>\n",
       "      <td>3168.121308</td>\n",
       "      <td>1644.457119</td>\n",
       "      <td>4135.218726</td>\n",
       "      <td>4168.066105</td>\n",
       "      <td>12597.703936</td>\n",
       "      <td>5141.078491</td>\n",
       "      <td>3233.053976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69734</th>\n",
       "      <td>2428.496265</td>\n",
       "      <td>640.044255</td>\n",
       "      <td>2219.144555</td>\n",
       "      <td>2016.197235</td>\n",
       "      <td>4135.218726</td>\n",
       "      <td>3955.781160</td>\n",
       "      <td>1177.953445</td>\n",
       "      <td>436.023439</td>\n",
       "      <td>240.838763</td>\n",
       "      <td>1427.321473</td>\n",
       "      <td>...</td>\n",
       "      <td>558.474333</td>\n",
       "      <td>5388.832120</td>\n",
       "      <td>248.482256</td>\n",
       "      <td>2389.056167</td>\n",
       "      <td>658.114397</td>\n",
       "      <td>3658.294165</td>\n",
       "      <td>3130.535499</td>\n",
       "      <td>4287.412464</td>\n",
       "      <td>4058.191026</td>\n",
       "      <td>232.372087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69811</th>\n",
       "      <td>2402.145677</td>\n",
       "      <td>657.977131</td>\n",
       "      <td>1515.374675</td>\n",
       "      <td>2220.289423</td>\n",
       "      <td>4168.066105</td>\n",
       "      <td>3760.888761</td>\n",
       "      <td>1368.172248</td>\n",
       "      <td>870.819036</td>\n",
       "      <td>93.965638</td>\n",
       "      <td>1284.569633</td>\n",
       "      <td>...</td>\n",
       "      <td>1031.824725</td>\n",
       "      <td>6721.278250</td>\n",
       "      <td>518.331964</td>\n",
       "      <td>2324.013737</td>\n",
       "      <td>1239.845769</td>\n",
       "      <td>3130.535499</td>\n",
       "      <td>4828.552600</td>\n",
       "      <td>5179.854463</td>\n",
       "      <td>4233.590055</td>\n",
       "      <td>322.924686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69891</th>\n",
       "      <td>3399.952878</td>\n",
       "      <td>1102.128801</td>\n",
       "      <td>9136.613955</td>\n",
       "      <td>4770.031955</td>\n",
       "      <td>12597.703936</td>\n",
       "      <td>5342.446677</td>\n",
       "      <td>1829.770565</td>\n",
       "      <td>3690.382602</td>\n",
       "      <td>322.950414</td>\n",
       "      <td>1773.053883</td>\n",
       "      <td>...</td>\n",
       "      <td>1447.841834</td>\n",
       "      <td>14191.034821</td>\n",
       "      <td>790.729612</td>\n",
       "      <td>2957.541204</td>\n",
       "      <td>1749.942124</td>\n",
       "      <td>4287.412464</td>\n",
       "      <td>5179.854463</td>\n",
       "      <td>12543.024118</td>\n",
       "      <td>5586.118143</td>\n",
       "      <td>2654.619554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69910</th>\n",
       "      <td>2989.466427</td>\n",
       "      <td>926.854822</td>\n",
       "      <td>2398.940668</td>\n",
       "      <td>2554.675586</td>\n",
       "      <td>5141.078491</td>\n",
       "      <td>4681.814310</td>\n",
       "      <td>1534.460839</td>\n",
       "      <td>729.556128</td>\n",
       "      <td>261.090672</td>\n",
       "      <td>1718.886282</td>\n",
       "      <td>...</td>\n",
       "      <td>918.166401</td>\n",
       "      <td>6938.946302</td>\n",
       "      <td>410.470269</td>\n",
       "      <td>2921.722811</td>\n",
       "      <td>1085.317040</td>\n",
       "      <td>4058.191026</td>\n",
       "      <td>4233.590055</td>\n",
       "      <td>5586.118143</td>\n",
       "      <td>5140.778449</td>\n",
       "      <td>336.507868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69967</th>\n",
       "      <td>299.564781</td>\n",
       "      <td>585.848312</td>\n",
       "      <td>2518.729878</td>\n",
       "      <td>1059.015963</td>\n",
       "      <td>3233.053976</td>\n",
       "      <td>433.155159</td>\n",
       "      <td>227.581495</td>\n",
       "      <td>1827.814329</td>\n",
       "      <td>246.999397</td>\n",
       "      <td>222.336294</td>\n",
       "      <td>...</td>\n",
       "      <td>536.086389</td>\n",
       "      <td>2928.562764</td>\n",
       "      <td>374.346329</td>\n",
       "      <td>235.095142</td>\n",
       "      <td>685.398335</td>\n",
       "      <td>232.372087</td>\n",
       "      <td>322.924686</td>\n",
       "      <td>2654.619554</td>\n",
       "      <td>336.507868</td>\n",
       "      <td>1692.250353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows x 615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Device_ID        124          148           174          242           266    \\\n",
       "Device_ID                                                                      \n",
       "124        2217.281915   802.394646   1644.651872  1572.076549   3225.376052   \n",
       "148         802.394646  2924.673893     49.767279   466.647514   1173.927569   \n",
       "174        1644.651872    49.767279  11129.711224  3156.693064  10030.564785   \n",
       "242        1572.076549   466.647514   3156.693064  6644.670539   4928.050491   \n",
       "266        3225.376052  1173.927569  10030.564785  4928.050491  14551.003949   \n",
       "...                ...          ...           ...          ...           ...   \n",
       "69734      2428.496265   640.044255   2219.144555  2016.197235   4135.218726   \n",
       "69811      2402.145677   657.977131   1515.374675  2220.289423   4168.066105   \n",
       "69891      3399.952878  1102.128801   9136.613955  4770.031955  12597.703936   \n",
       "69910      2989.466427   926.854822   2398.940668  2554.675586   5141.078491   \n",
       "69967       299.564781   585.848312   2518.729878  1059.015963   3233.053976   \n",
       "\n",
       "Device_ID        279          438          610         642          688    \\\n",
       "Device_ID                                                                   \n",
       "124        3065.667643  1002.485923   683.146132  216.999755  1254.956756   \n",
       "148        1184.646557   634.057473  1503.602376  565.255376   737.214188   \n",
       "174        3040.518387   628.336661  2863.376915  135.468064   589.841859   \n",
       "242        2362.428871   806.440792  1317.343908  170.283444   925.939938   \n",
       "266        5003.606356  1717.602201  4112.996933  442.822017  1806.132237   \n",
       "...                ...          ...          ...         ...          ...   \n",
       "69734      3955.781160  1177.953445   436.023439  240.838763  1427.321473   \n",
       "69811      3760.888761  1368.172248   870.819036   93.965638  1284.569633   \n",
       "69891      5342.446677  1829.770565  3690.382602  322.950414  1773.053883   \n",
       "69910      4681.814310  1534.460839   729.556128  261.090672  1718.886282   \n",
       "69967       433.155159   227.581495  1827.814329  246.999397   222.336294   \n",
       "\n",
       "Device_ID  ...        68884         68901       69158        69207  \\\n",
       "Device_ID  ...                                                       \n",
       "124        ...   800.323922   4771.101910  378.968807  2087.473928   \n",
       "148        ...  1710.937432   2264.690736  687.826019   621.614319   \n",
       "174        ...    47.867393   9809.372937  117.110728  1045.156915   \n",
       "242        ...   540.884430   7242.237116  311.206679  1458.544681   \n",
       "266        ...  1375.383078  14458.096890  791.676832  3168.121308   \n",
       "...        ...          ...           ...         ...          ...   \n",
       "69734      ...   558.474333   5388.832120  248.482256  2389.056167   \n",
       "69811      ...  1031.824725   6721.278250  518.331964  2324.013737   \n",
       "69891      ...  1447.841834  14191.034821  790.729612  2957.541204   \n",
       "69910      ...   918.166401   6938.946302  410.470269  2921.722811   \n",
       "69967      ...   536.086389   2928.562764  374.346329   235.095142   \n",
       "\n",
       "Device_ID        69449        69734        69811         69891        69910  \\\n",
       "Device_ID                                                                     \n",
       "124        1000.364462  2428.496265  2402.145677   3399.952878  2989.466427   \n",
       "148        2295.599464   640.044255   657.977131   1102.128801   926.854822   \n",
       "174          44.900549  2219.144555  1515.374675   9136.613955  2398.940668   \n",
       "242         663.470648  2016.197235  2220.289423   4770.031955  2554.675586   \n",
       "266        1644.457119  4135.218726  4168.066105  12597.703936  5141.078491   \n",
       "...                ...          ...          ...           ...          ...   \n",
       "69734       658.114397  3658.294165  3130.535499   4287.412464  4058.191026   \n",
       "69811      1239.845769  3130.535499  4828.552600   5179.854463  4233.590055   \n",
       "69891      1749.942124  4287.412464  5179.854463  12543.024118  5586.118143   \n",
       "69910      1085.317040  4058.191026  4233.590055   5586.118143  5140.778449   \n",
       "69967       685.398335   232.372087   322.924686   2654.619554   336.507868   \n",
       "\n",
       "Device_ID        69967  \n",
       "Device_ID               \n",
       "124         299.564781  \n",
       "148         585.848312  \n",
       "174        2518.729878  \n",
       "242        1059.015963  \n",
       "266        3233.053976  \n",
       "...                ...  \n",
       "69734       232.372087  \n",
       "69811       322.924686  \n",
       "69891      2654.619554  \n",
       "69910       336.507868  \n",
       "69967      1692.250353  \n",
       "\n",
       "[615 rows x 615 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "Corrected covariance: (188805, 4)\n",
      "Device fractions: (288008, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get domain counts and create pivot matrix\n",
    "\n",
    "# Compute covariance matrix and melt it\n",
    "covariance_matrix = compute_chunked_covariance(pivot_matrix)\n",
    "melted_cov = melt_covariance_matrix(covariance_matrix)\n",
    "\n",
    "# Apply filtering and transformation to covariance\n",
    "corrected_cov = filter_and_transform_covariance(melted_cov)\n",
    "\n",
    "# Get device domain fractions from original domain counts\n",
    "device_fractions = get_device_domain_fractions(domain_counts)\n",
    "# Compute domain-target correlations\n",
    "domain_correlations = compute_domain_target_correlation(domain_counts)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(f\"Corrected covariance: {corrected_cov.shape}\")\n",
    "print(f\"Device fractions: {device_fractions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_model_funcs.py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "def create_graph_data(corrected_cov):\n",
    "    # Convert domain names to numerical indices\n",
    "    unique_domains = pd.concat([corrected_cov['source'], corrected_cov['target']]).unique()\n",
    "    domain_to_idx = {domain: idx for idx, domain in enumerate(unique_domains)}\n",
    "    \n",
    "    # Create edge index and edge weights\n",
    "    edge_index = torch.tensor([\n",
    "        [domain_to_idx[s] for s in corrected_cov['source']],\n",
    "        [domain_to_idx[t] for t in corrected_cov['target']]\n",
    "    ], dtype=torch.long)\n",
    "    \n",
    "    edge_weight = torch.tensor(corrected_cov['corrected_cov'].values, dtype=torch.float)\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    data = Data(\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_weight,\n",
    "        num_nodes=len(unique_domains)\n",
    "    )\n",
    "    return data, domain_to_idx\n",
    "\n",
    "def train_node2vec(data, device='cuda', epochs=100):\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model = Node2Vec(\n",
    "        data.edge_index,\n",
    "        embedding_dim=128,\n",
    "        walk_length=20,\n",
    "        context_size=10,\n",
    "        walks_per_node=10,\n",
    "        p=1,\n",
    "        q=1,\n",
    "        sparse=True\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n",
    "            \n",
    "    return model\n",
    "@ray.remote\n",
    "def _compute_device_embedding(device_id, group, embeddings, domain_mapping):\n",
    "    valid_embeddings = []\n",
    "    valid_weights = []\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        domain = row['Domain_Name']\n",
    "        if domain in domain_mapping:\n",
    "            idx = domain_mapping[domain]\n",
    "            valid_embeddings.append(embeddings[idx])\n",
    "            valid_weights.append(row['fraction'])\n",
    "    \n",
    "    if valid_embeddings:\n",
    "        valid_weights = np.array(valid_weights)\n",
    "        valid_weights = valid_weights / valid_weights.sum()\n",
    "        device_embedding = np.average(valid_embeddings, weights=valid_weights, axis=0)\n",
    "        return device_id, device_embedding\n",
    "    return device_id, None\n",
    "\n",
    "def compute_device_embeddings(device_fractions, embeddings, domain_mapping):\n",
    "    # Group device fractions by Device_ID\n",
    "    grouped_fractions = device_fractions.groupby('Device_ID')\n",
    "    \n",
    "    # Create remote tasks\n",
    "    futures = [\n",
    "        _compute_device_embedding.remote(device_id, group, embeddings, domain_mapping)\n",
    "        for device_id, group in grouped_fractions\n",
    "    ]\n",
    "    \n",
    "    # Collect results\n",
    "    results = ray.get(futures)\n",
    "    \n",
    "    # Convert results to dictionary\n",
    "    device_embeddings = {\n",
    "        device_id: embedding \n",
    "        for device_id, embedding in results \n",
    "        if embedding is not None\n",
    "    }\n",
    "    \n",
    "    return device_embeddings\n",
    "\n",
    "# Main flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = get_train_test_masks(domain_counts)\n",
    "data, domain_mapping = create_graph_data(corrected_cov)\n",
    "\n",
    "model = train_node2vec(data)\n",
    "embeddings = model().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Test Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
